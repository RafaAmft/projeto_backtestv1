# üìò Boas Pr√°ticas de C√≥digo ‚Äì Cursora AI

**Vers√£o:** 1.1.0  
**Data:** 06/10/2025  
**Status:** Est√°vel

Guia de refer√™ncia para manter consist√™ncia, qualidade e seguran√ßa no desenvolvimento em **Python backend** e **an√°lise de dados**.

---

## üìã Changelog

### [1.1.0] - 2025-10-06
#### Adicionado
- Exemplos pr√°ticos de Conventional Commits
- Estrutura de projeto completa e corrigida
- Se√ß√£o expandida sobre nomenclaturas Python
- Exemplos de testes com pytest (fixtures, mocks, parametriza√ß√£o)
- Complementos para an√°lise de dados financeiros
- Se√ß√£o completa de CI/CD com GitHub Actions
- Exemplos de Docker e pre-commit hooks
- Valida√ß√£o de dados financeiros

#### Corrigido
- Formata√ß√£o da estrutura de projeto
- Organiza√ß√£o visual do documento

### [1.0.0] - 2025-07-08
- Vers√£o inicial do guia

---

## üîπ Git Workflow

### Commits Descritivos
- Use [Conventional Commits](https://www.conventionalcommits.org/) para padroniza√ß√£o.
- PRs devem ter pelo menos 1 revis√£o aprovada antes do merge.
- Adote versionamento sem√¢ntico (**semver**): `major.minor.patch`.
- Nunca commitar `.env`, `venv/`, `__pycache__/` ou dados sens√≠veis.

### Exemplos de Commits:
```bash
feat: adicionar suporte para fundos imobili√°rios
fix: corrigir c√°lculo do Sharpe Ratio
docs: atualizar README com exemplos de uso
refactor: reorganizar estrutura de cache
test: adicionar testes para portfolio_collector
perf: otimizar consultas ao banco de dados
chore: atualizar depend√™ncias do projeto
style: formatar c√≥digo com black
```

### Branch Strategy (GitFlow):
```
main (produ√ß√£o)
  ‚Üë
  ‚îî‚îÄ‚îÄ release/v1.1.0
        ‚Üë
        ‚îî‚îÄ‚îÄ develop (homologa√ß√£o)
              ‚Üë
              ‚îú‚îÄ‚îÄ feature/nova-funcionalidade
              ‚îú‚îÄ‚îÄ feature/suporte-fundos-imobiliarios
              ‚îî‚îÄ‚îÄ fix/corrigir-sharpe-ratio
```

### Tags e Versionamento:
```bash
# Criar tag anotada
git tag -a v1.1.0 -m "Vers√£o 1.1.0 - Melhorias e corre√ß√µes"

# Enviar tags para reposit√≥rio remoto
git push origin v1.1.0

# Listar todas as tags
git tag -l
```

---

## üîπ Estrutura de Projeto

```
project_root/
‚îú‚îÄ‚îÄ src/                      # C√≥digo fonte principal
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ core/                # L√≥gica de neg√≥cio
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ portfolio.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ market_indices.py
‚îÇ   ‚îú‚îÄ‚îÄ apis/                # Integra√ß√µes com APIs externas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ binance_api.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ yahoo_api.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cvm_api.py
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/           # Interface e visualiza√ß√£o
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ portfolio_collector.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/               # Utilit√°rios e helpers
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ validators.py
‚îú‚îÄ‚îÄ tests/                   # Testes automatizados
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ unit/               # Testes unit√°rios
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_portfolio.py
‚îÇ   ‚îú‚îÄ‚îÄ integration/        # Testes de integra√ß√£o
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_apis.py
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/           # Dados de teste
‚îÇ       ‚îî‚îÄ‚îÄ sample_data.json
‚îú‚îÄ‚îÄ data/                    # Dados (gitignored se sens√≠vel)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Dados brutos originais
‚îÇ   ‚îú‚îÄ‚îÄ processed/          # Dados processados
‚îÇ   ‚îî‚îÄ‚îÄ cache/              # Cache tempor√°rio
‚îú‚îÄ‚îÄ docs/                    # Documenta√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îî‚îÄ‚îÄ API.md
‚îú‚îÄ‚îÄ scripts/                 # Scripts auxiliares
‚îÇ   ‚îú‚îÄ‚îÄ setup.py
‚îÇ   ‚îî‚îÄ‚îÄ data_download.py
‚îú‚îÄ‚îÄ config/                  # Arquivos de configura√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml
‚îÇ   ‚îî‚îÄ‚îÄ config.example.yaml
‚îú‚îÄ‚îÄ relatorios/             # Relat√≥rios gerados
‚îÇ   ‚îú‚îÄ‚îÄ portfolio/
‚îÇ   ‚îî‚îÄ‚îÄ executivo/
‚îú‚îÄ‚îÄ .env.example            # Template de vari√°veis de ambiente
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .gitattributes
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias Python
‚îú‚îÄ‚îÄ pyproject.toml          # Configura√ß√£o do projeto (Poetry/setuptools)
‚îú‚îÄ‚îÄ README.md               # Documenta√ß√£o principal
‚îú‚îÄ‚îÄ CHANGELOG.md            # Hist√≥rico de mudan√ßas
‚îî‚îÄ‚îÄ boaspraticas.md         # Este arquivo
```

### Princ√≠pios:
- ‚úÖ C√≥digo de produ√ß√£o em `src/`
- ‚úÖ Testes separados em `tests/`
- ‚úÖ Depend√™ncias sempre declaradas em `requirements.txt` ou `pyproject.toml`
- ‚úÖ Configura√ß√µes em arquivos separados, nunca hardcoded
- ‚úÖ Dados sens√≠veis sempre no `.gitignore`

---

## üîπ Python

### Configura√ß√£o B√°sica
- **Vers√£o**: Padronizar Python >= 3.10 (recomendado 3.11+).
- **Estilo**: Seguir [PEP 8](https://peps.python.org/pep-0008/).
- **Tipagem**: Usar `type hints` em fun√ß√µes p√∫blicas.
- **Docstrings**: Seguir [PEP 257](https://peps.python.org/pep-0257/).

### Conven√ß√µes de Nomenclatura
```python
# Classes: PascalCase
class PortfolioAnalyzer:
    pass

# Fun√ß√µes e vari√°veis: snake_case
def calculate_sharpe_ratio(returns: list) -> float:
    pass

# Constantes: UPPER_SNAKE_CASE
MAX_PORTFOLIO_SIZE = 1000000
API_TIMEOUT = 30

# M√©todos privados: prefixo _
def _internal_validation(self):
    pass

# Vari√°veis privadas de classe: prefixo __
class MyClass:
    __private_attr = "value"
```

### Imports
```python
# Ordem: stdlib ‚Üí terceiros ‚Üí locais
import os
import sys
from datetime import datetime

import pandas as pd
import numpy as np
from requests import Session

from src.core.portfolio import Portfolio
from src.utils.validators import validate_cnpj
```
- ‚úÖ Preferir imports absolutos
- ‚úÖ Agrupar imports por categoria
- ‚úÖ Ordenar alfabeticamente dentro de cada grupo

### Type Hints
```python
from typing import List, Dict, Optional, Union
from decimal import Decimal

def calculate_returns(
    prices: List[float],
    period: int = 252,
    annualize: bool = True
) -> Dict[str, float]:
    """Calcula retornos de uma s√©rie de pre√ßos.
    
    Args:
        prices: Lista de pre√ßos hist√≥ricos
        period: Per√≠odo para c√°lculo (padr√£o: 252 dias √∫teis)
        annualize: Se True, anualiza os retornos
    
    Returns:
        Dicion√°rio com m√©tricas de retorno
        
    Raises:
        ValueError: Se prices estiver vazio
    """
    if not prices:
        raise ValueError("Lista de pre√ßos n√£o pode estar vazia")
    
    # implementa√ß√£o...
    return {"mean": 0.0, "std": 0.0}
```

### Logging (nunca usar print() em produ√ß√£o)
```python
import logging

# Configura√ß√£o b√°sica
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Uso
logger.debug("Detalhes de debug")
logger.info("Processando carteira: %s", portfolio_name)
logger.warning("Cache desatualizado, recarregando dados")
logger.error("Erro ao buscar dados da API: %s", error)
logger.critical("Falha cr√≠tica no sistema")
```

### Tratamento de Erros
```python
# ‚ùå Evitar gen√©rico
try:
    result = calculate_something()
except Exception as e:
    print(e)

# ‚úÖ Usar exce√ß√µes espec√≠ficas
try:
    result = calculate_sharpe_ratio(returns)
except ValueError as e:
    logger.error(f"Dados inv√°lidos para c√°lculo: {e}")
    raise
except ZeroDivisionError:
    logger.warning("Volatilidade zero detectada, retornando 0")
    return 0.0

# ‚úÖ Criar exce√ß√µes customizadas
class PortfolioValidationError(Exception):
    """Exce√ß√£o para erros de valida√ß√£o de carteira"""
    pass

def validate_portfolio(portfolio: Dict) -> None:
    if portfolio['value'] <= 0:
        raise PortfolioValidationError(
            f"Valor da carteira deve ser positivo, recebido: {portfolio['value']}"
        )
```

### Context Managers
```python
# ‚úÖ Sempre usar para gerenciar recursos
with open('data.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

# Para conex√µes de banco
from sqlalchemy import create_engine

engine = create_engine('postgresql://...')
with engine.connect() as conn:
    result = conn.execute(query)
    
# Custom context manager
from contextlib import contextmanager

@contextmanager
def temporary_cache():
    cache = {}
    try:
        yield cache
    finally:
        cache.clear()
```

### Configura√ß√µes (nunca hardcoded)
```python
import os
from dotenv import load_dotenv

load_dotenv()

# ‚ùå Nunca fazer isso
API_KEY = "abc123xyz"
DATABASE_URL = "postgresql://user:pass@localhost/db"

# ‚úÖ Usar vari√°veis de ambiente
API_KEY = os.getenv("API_KEY")
DATABASE_URL = os.getenv("DATABASE_URL")

# ‚úÖ Com valores padr√£o e valida√ß√£o
API_TIMEOUT = int(os.getenv("API_TIMEOUT", "30"))

if not API_KEY:
    raise EnvironmentError("API_KEY n√£o configurada")
```

### Performance
```python
# ‚úÖ List comprehensions (mais r√°pido)
squares = [x**2 for x in range(1000)]

# ‚úÖ Generator expressions (economia de mem√≥ria)
sum_squares = sum(x**2 for x in range(1000000))

# ‚úÖ Use yield para datasets grandes
def read_large_file(file_path: str):
    with open(file_path) as f:
        for line in f:
            yield line.strip()

# ‚úÖ Profiling quando necess√°rio
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()
# c√≥digo a perfilar
profiler.disable()

stats = pstats.Stats(profiler)
stats.sort_stats('cumulative')
stats.print_stats(10)  # Top 10 fun√ß√µes mais lentas
```

### Gerenciamento de Depend√™ncias
```txt
# requirements.txt - Fixar vers√µes em produ√ß√£o
pandas==2.0.3
numpy==1.24.4
yfinance==0.2.28

# Ou com ranges compat√≠veis
requests>=2.28.0,<3.0.0  # Aceita patches e minors da v2
scipy~=1.11.0            # Aceita apenas patches (1.11.x)
```

---

## üîπ Testes

### Configura√ß√£o
- **Framework**: pytest (recomendado)
- **Nomenclatura**: Arquivos `test_*.py` ou `*_test.py`
- **Cobertura m√≠nima**: 80% (ideal: 90%+)
- **Estrutura**:
  - **Unit√°rios** ‚Üí Fun√ß√µes isoladas
  - **Integra√ß√£o** ‚Üí Intera√ß√£o entre m√≥dulos
  - **E2E** (end-to-end) ‚Üí Fluxos completos

### Estrutura B√°sica de Teste (AAA Pattern)
```python
# tests/unit/test_portfolio.py
import pytest
from src.core.portfolio import Portfolio

def test_calculate_sharpe_ratio():
    """Testa c√°lculo do Sharpe Ratio"""
    # Arrange (Preparar)
    portfolio = Portfolio(value=100000)
    portfolio.returns = [0.01, 0.02, -0.01, 0.03]
    expected_ratio = 0.53
    
    # Act (Agir)
    result = portfolio.calculate_sharpe_ratio()
    
    # Assert (Verificar)
    assert abs(result - expected_ratio) < 0.01
    assert isinstance(result, float)
```

### Fixtures (Dados Reutiliz√°veis)
```python
import pytest
from datetime import datetime

@pytest.fixture
def sample_portfolio():
    """Fixture de carteira padr√£o para testes"""
    return Portfolio(
        value=100000,
        assets=[
            {"name": "PETR4", "value": 40000},
            {"name": "VALE3", "value": 60000}
        ],
        created_at=datetime(2025, 1, 1)
    )

@pytest.fixture
def mock_market_data():
    """Fixture com dados de mercado simulados"""
    return {
        "PETR4": {"price": 32.50, "volume": 1000000},
        "VALE3": {"price": 54.60, "volume": 800000}
    }

def test_portfolio_allocation(sample_portfolio):
    """Usa fixture para testar aloca√ß√£o"""
    allocation = sample_portfolio.get_allocation()
    assert allocation["PETR4"] == 0.4
    assert allocation["VALE3"] == 0.6
```

### Mocking APIs Externas
```python
from unittest.mock import patch, MagicMock
import pytest

@pytest.fixture
def mock_binance_api(monkeypatch):
    """Mock da API Binance"""
    def mock_get_price(symbol):
        prices = {
            "BTCUSDT": 50000.0,
            "ETHUSDT": 3000.0
        }
        return prices.get(symbol, 0.0)
    
    monkeypatch.setattr("src.apis.binance_api.get_price", mock_get_price)

def test_crypto_portfolio_value(mock_binance_api):
    """Testa valor de carteira cripto com API mockada"""
    portfolio = CryptoPortfolio({"BTCUSDT": 1, "ETHUSDT": 10})
    
    expected_value = 50000 + (10 * 3000)  # 80000
    assert portfolio.get_total_value() == expected_value

# Usando @patch decorator
@patch('src.apis.yahoo_api.yfinance.download')
def test_fetch_stock_data(mock_download):
    """Mock do yfinance.download"""
    mock_download.return_value = pd.DataFrame({
        'Close': [32.5, 33.0, 32.8]
    })
    
    data = fetch_stock_data("PETR4.SA")
    assert len(data) == 3
    assert data['Close'].iloc[0] == 32.5
```

### Testes Parametrizados
```python
@pytest.mark.parametrize("value,expected_tier", [
    (10000, "bronze"),
    (100000, "silver"),
    (500000, "gold"),
    (1000000, "platinum"),
])
def test_portfolio_tier(value, expected_tier):
    """Testa classifica√ß√£o de carteira por valor"""
    portfolio = Portfolio(value=value)
    assert portfolio.get_tier() == expected_tier

@pytest.mark.parametrize("returns,expected", [
    ([0.01, 0.02, 0.03], 0.02),  # M√©dia positiva
    ([-0.01, -0.02, -0.03], -0.02),  # M√©dia negativa
    ([0, 0, 0], 0.0),  # Zero
])
def test_average_return(returns, expected):
    """Testa c√°lculo de retorno m√©dio"""
    result = calculate_average_return(returns)
    assert abs(result - expected) < 0.001
```

### Testando Exce√ß√µes
```python
def test_negative_portfolio_value_raises_error():
    """Verifica se valor negativo levanta exce√ß√£o"""
    with pytest.raises(ValueError, match="Valor deve ser positivo"):
        Portfolio(value=-1000)

def test_empty_returns_raises_error():
    """Verifica erro ao calcular Sharpe sem retornos"""
    portfolio = Portfolio(value=100000)
    with pytest.raises(ValueError) as exc_info:
        portfolio.calculate_sharpe_ratio()
    
    assert "retornos vazia" in str(exc_info.value).lower()
```

### Markers (Categoriza√ß√£o de Testes)
```python
@pytest.mark.slow
def test_large_dataset_processing():
    """Teste lento com dataset grande"""
    data = load_large_dataset()
    result = process_data(data)
    assert len(result) > 1000000

@pytest.mark.integration
def test_api_integration():
    """Teste de integra√ß√£o com API real"""
    api = BinanceAPI()
    price = api.get_price("BTCUSDT")
    assert price > 0

@pytest.mark.skip(reason="API temporariamente indispon√≠vel")
def test_external_api():
    """Teste a ser pulado"""
    pass

# Executar apenas testes r√°pidos:
# pytest -m "not slow"
# Executar apenas integra√ß√£o:
# pytest -m integration
```

### Cobertura de C√≥digo
```bash
# Instalar pytest-cov
pip install pytest-cov

# Executar com relat√≥rio de cobertura
pytest --cov=src --cov-report=html --cov-report=term

# Ver relat√≥rio detalhado
# Abre: htmlcov/index.html

# Falhar se cobertura < 80%
pytest --cov=src --cov-fail-under=80
```

### Configura√ß√£o pytest.ini
```ini
# pytest.ini
[pytest]
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Markers customizados
markers =
    slow: marca testes lentos
    integration: testes de integra√ß√£o
    unit: testes unit√°rios
    api: testes que usam APIs externas

# Op√ß√µes padr√£o
addopts = 
    --verbose
    --strict-markers
    --cov=src
    --cov-report=term-missing
    --cov-report=html

# Ignorar warnings espec√≠ficos
filterwarnings =
    ignore::DeprecationWarning
```

---

## üîπ An√°lise de Dados

### Ambiente e Depend√™ncias
- **Ambientes virtuais**: Sempre usar `venv`, `poetry`, ou `conda`
- **Fixar vers√µes**: Todas as bibliotecas em `requirements.txt`
- **Bibliotecas essenciais**:
  - Manipula√ß√£o: `pandas`, `polars` (para grandes volumes)
  - Num√©rico: `numpy`, `scipy`
  - Visualiza√ß√£o: `matplotlib`, `seaborn`, `plotly`
  - Banco de dados: `sqlalchemy`, `duckdb`
  - Finan√ßas: `yfinance`, `pandas-datareader`

### Boas Pr√°ticas Gerais
```python
import pandas as pd
import numpy as np

# ‚úÖ Sempre manter c√≥pia dos dados originais
df_raw = pd.read_csv('data.csv')
df = df_raw.copy()

# ‚úÖ Normalizar nomes de colunas (snake_case)
df.columns = df.columns.str.lower().str.replace(' ', '_')

# ‚úÖ Definir tipos de dados explicitamente
df = df.astype({
    'data': 'datetime64[ns]',
    'valor': 'float64',
    'ticker': 'string'
})

# ‚úÖ Usar query() para filtros leg√≠veis
df_filtered = df.query('valor > 1000 and ticker == "PETR4"')

# ‚ùå Evitar loops em pandas
# Ruim:
for idx, row in df.iterrows():
    df.at[idx, 'result'] = row['price'] * row['quantity']

# ‚úÖ Bom: usar vetoriza√ß√£o
df['result'] = df['price'] * df['quantity']

# ‚úÖ Para opera√ß√µes complexas, usar apply
df['category'] = df['value'].apply(lambda x: 'high' if x > 1000 else 'low')

# ‚úÖ Ou ainda melhor: np.where ou pd.cut
df['category'] = np.where(df['value'] > 1000, 'high', 'low')
```

### S√©ries Temporais Financeiras
```python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# ‚úÖ Sempre definir √≠ndice temporal
df['data'] = pd.to_datetime(df['data'])
df.set_index('data', inplace=True)
df.sort_index(inplace=True)

# ‚úÖ Reamostrar dados (di√°rio ‚Üí mensal)
df_monthly = df.resample('M').last()  # √öltimo valor do m√™s
df_monthly_avg = df.resample('M').mean()  # M√©dia mensal

# ‚úÖ Tratar dados faltantes em s√©ries financeiras
df.fillna(method='ffill', inplace=True)  # Forward fill (propaga √∫ltimo valor)
df.fillna(method='bfill', inplace=True)  # Backward fill

# ‚úÖ Calcular retornos
# Retornos simples
df['return_simple'] = df['price'].pct_change()

# Retornos logar√≠tmicos (mais precisos para an√°lise)
df['return_log'] = np.log(df['price'] / df['price'].shift(1))

# ‚úÖ Retornos acumulados
df['cumulative_return'] = (1 + df['return_simple']).cumprod() - 1

# ‚úÖ Volatilidade m√≥vel (janela de 30 dias)
df['volatility_30d'] = df['return_log'].rolling(window=30).std()

# ‚úÖ M√©dias m√≥veis
df['sma_50'] = df['price'].rolling(window=50).mean()  # M√©dia simples
df['ema_50'] = df['price'].ewm(span=50).mean()  # M√©dia exponencial
```

### C√°lculos Financeiros Essenciais
```python
import numpy as np
import pandas as pd

def calculate_returns(prices: pd.Series) -> pd.Series:
    """Calcula retornos logar√≠tmicos"""
    return np.log(prices / prices.shift(1))

def calculate_volatility(returns: pd.Series, annualize: bool = True) -> float:
    """Calcula volatilidade (anualizada para trading days)"""
    vol = returns.std()
    if annualize:
        vol = vol * np.sqrt(252)  # 252 dias √∫teis
    return vol

def calculate_sharpe_ratio(returns: pd.Series, risk_free_rate: float = 0.0) -> float:
    """Calcula Sharpe Ratio"""
    excess_returns = returns - risk_free_rate / 252  # Di√°rio
    if returns.std() == 0:
        return 0.0
    return (excess_returns.mean() / excess_returns.std()) * np.sqrt(252)

def calculate_max_drawdown(returns: pd.Series) -> float:
    """Calcula Maximum Drawdown"""
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.cummax()
    drawdown = (cumulative - running_max) / running_max
    return drawdown.min()

def calculate_cagr(prices: pd.Series) -> float:
    """Calcula CAGR (Compound Annual Growth Rate)"""
    n_years = len(prices) / 252  # Assumindo dados di√°rios
    total_return = (prices.iloc[-1] / prices.iloc[0]) - 1
    return (1 + total_return) ** (1 / n_years) - 1

# ‚úÖ Exemplo de uso
returns = calculate_returns(df['price'])
print(f"Volatilidade anualizada: {calculate_volatility(returns):.2%}")
print(f"Sharpe Ratio: {calculate_sharpe_ratio(returns):.2f}")
print(f"Max Drawdown: {calculate_max_drawdown(returns):.2%}")
print(f"CAGR: {calculate_cagr(df['price']):.2%}")
```

### Valida√ß√£o de Dados Financeiros
```python
import pandas as pd
import numpy as np

def validate_financial_data(df: pd.DataFrame) -> None:
    """Valida consist√™ncia de dados financeiros"""
    
    # Verificar valores nulos
    null_counts = df.isnull().sum()
    if null_counts.any():
        print(f"‚ö†Ô∏è Valores nulos encontrados:\n{null_counts[null_counts > 0]}")
    
    # Verificar pre√ßos negativos
    if 'price' in df.columns:
        negative_prices = (df['price'] < 0).sum()
        assert negative_prices == 0, f"‚ùå {negative_prices} pre√ßos negativos detectados"
    
    # Verificar ordem cronol√≥gica
    if df.index.name == 'data' or 'data' in df.columns:
        assert df.index.is_monotonic_increasing, "‚ùå Datas fora de ordem"
    
    # Verificar outliers extremos (mais de 50% de varia√ß√£o di√°ria)
    if 'return_simple' in df.columns:
        extreme_returns = df[abs(df['return_simple']) > 0.5]
        if len(extreme_returns) > 0:
            print(f"‚ö†Ô∏è {len(extreme_returns)} retornos extremos (>50%) detectados")
    
    print("‚úÖ Valida√ß√£o conclu√≠da")

# Exemplo de uso
validate_financial_data(df)
```

### Cache para Dados de Mercado
```python
import functools
from datetime import datetime, timedelta
import pickle
import os

def cache_to_disk(cache_dir: str = 'cache_temp', expiry_hours: int = 24):
    """Decorator para cachear resultados em disco"""
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # Criar chave de cache
            cache_key = f"{func.__name__}_{str(args)}_{str(kwargs)}.pkl"
            cache_path = os.path.join(cache_dir, cache_key)
            
            # Verificar se cache existe e √© v√°lido
            if os.path.exists(cache_path):
                age = datetime.now() - datetime.fromtimestamp(os.path.getmtime(cache_path))
                if age < timedelta(hours=expiry_hours):
                    with open(cache_path, 'rb') as f:
                        return pickle.load(f)
            
            # Executar fun√ß√£o e cachear resultado
            result = func(*args, **kwargs)
            os.makedirs(cache_dir, exist_ok=True)
            with open(cache_path, 'wb') as f:
                pickle.dump(result, f)
            
            return result
        return wrapper
    return decorator

# Uso
@cache_to_disk(cache_dir='data/cache', expiry_hours=24)
def get_stock_data(ticker: str, start_date: str):
    """Busca dados de a√ß√µes com cache"""
    import yfinance as yf
    return yf.download(ticker, start=start_date, progress=False)
```

### Visualiza√ß√£o de Dados Financeiros
```python
import matplotlib.pyplot as plt
import seaborn as sns

# ‚úÖ Configurar estilo consistente
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

def plot_price_and_volume(df: pd.DataFrame, ticker: str):
    """Gr√°fico de pre√ßo e volume"""
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)
    
    # Pre√ßo
    ax1.plot(df.index, df['close'], label='Pre√ßo de Fechamento', linewidth=2)
    ax1.fill_between(df.index, df['low'], df['high'], alpha=0.3, label='Min-Max')
    ax1.set_ylabel('Pre√ßo (R$)', fontsize=12)
    ax1.set_title(f'{ticker} - Evolu√ß√£o de Pre√ßo e Volume', fontsize=14, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Volume
    ax2.bar(df.index, df['volume'], alpha=0.7, color='steelblue')
    ax2.set_ylabel('Volume', fontsize=12)
    ax2.set_xlabel('Data', fontsize=12)
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'relatorios/graficos/{ticker}_price_volume.png', dpi=300, bbox_inches='tight')
    plt.show()

def plot_returns_distribution(returns: pd.Series):
    """Histograma de distribui√ß√£o de retornos"""
    fig, ax = plt.subplots(figsize=(10, 6))
    
    ax.hist(returns.dropna(), bins=50, alpha=0.7, edgecolor='black')
    ax.axvline(returns.mean(), color='red', linestyle='--', linewidth=2, label=f'M√©dia: {returns.mean():.2%}')
    ax.axvline(0, color='black', linestyle='-', linewidth=1)
    
    ax.set_xlabel('Retorno', fontsize=12)
    ax.set_ylabel('Frequ√™ncia', fontsize=12)
    ax.set_title('Distribui√ß√£o de Retornos', fontsize=14, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
```

### Reprodutibilidade
```python
import numpy as np
import random

# ‚úÖ Fixar seeds para resultados reproduz√≠veis
RANDOM_SEED = 42

np.random.seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

# Para bibliotecas espec√≠ficas
import tensorflow as tf
tf.random.set_seed(RANDOM_SEED)

# ‚úÖ Scripts devem rodar do in√≠cio ao fim
# Estrutura recomendada:
if __name__ == "__main__":
    # 1. Carregar dados
    df = load_data()
    
    # 2. Processar
    df_processed = process_data(df)
    
    # 3. Analisar
    results = analyze_data(df_processed)
    
    # 4. Visualizar
    plot_results(results)
    
    # 5. Salvar
    save_results(results, 'relatorios/analise.json')
```

### Seguran√ßa de Dados (LGPD)
```python
import hashlib
import re

def anonimizar_cpf(cpf: str) -> str:
    """Anonimiza CPF para LGPD"""
    return f"***.***.{cpf[-6:]}"

def hash_sensitive_data(data: str) -> str:
    """Cria hash irrevers√≠vel de dados sens√≠veis"""
    return hashlib.sha256(data.encode()).hexdigest()

def remover_pii(df: pd.DataFrame) -> pd.DataFrame:
    """Remove informa√ß√µes pessoais identific√°veis"""
    pii_columns = ['cpf', 'nome', 'email', 'telefone', 'endereco']
    df_clean = df.drop(columns=[col for col in pii_columns if col in df.columns])
    return df_clean

# ‚úÖ Sempre anonimizar antes de exportar
df_export = remover_pii(df)
df_export.to_csv('dados_anonimizados.csv', index=False)
```

### Performance para Grandes Datasets
```python
# ‚úÖ Para datasets grandes (> 1GB), usar Polars
import polars as pl

# Polars √© mais r√°pido que Pandas para grandes volumes
df_polars = pl.read_csv('large_dataset.csv')
result = df_polars.filter(pl.col('value') > 1000).groupby('category').agg(pl.col('value').mean())

# ‚úÖ Ou usar Dask para processamento paralelo
import dask.dataframe as dd

df_dask = dd.read_csv('large_dataset*.csv')
result = df_dask.groupby('category')['value'].mean().compute()

# ‚úÖ Chunking para leitura de arquivos grandes
for chunk in pd.read_csv('large_file.csv', chunksize=10000):
    process_chunk(chunk)
```

---

## üîπ Deploy / CI-CD

### Ambientes
- **Development**: Ambiente local com dados de teste
- **Staging/Homologa√ß√£o**: Dados simulados ou anonimizados
- **Production**: Dados reais, monitoramento ativo

### Pipeline M√≠nimo (CI/CD)
```
1. Lint (Verificar c√≥digo)
2. Tests (Executar testes)
3. Build (Construir aplica√ß√£o)
4. Security Scan (Verificar vulnerabilidades)
5. Deploy (Implantar)
```

### GitHub Actions - Exemplo Completo
```yaml
# .github/workflows/ci.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]

jobs:
  lint:
    name: Lint & Code Quality
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install linting tools
        run: |
          pip install black flake8 isort mypy
      
      - name: Run Black
        run: black --check src/
      
      - name: Run Flake8
        run: flake8 src/ --max-line-length=100
      
      - name: Run isort
        run: isort --check-only src/
      
      - name: Run mypy
        run: mypy src/ --ignore-missing-imports

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov
      
      - name: Run tests with coverage
        run: |
          pytest --cov=src --cov-report=xml --cov-report=term
      
      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: true
      
      - name: Check coverage threshold
        run: |
          pytest --cov=src --cov-fail-under=80

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: test
    steps:
      - uses: actions/checkout@v3
      
      - name: Run Bandit (security linter)
        run: |
          pip install bandit
          bandit -r src/ -f json -o bandit-report.json
      
      - name: Run Safety (dependency check)
        run: |
          pip install safety
          safety check --json

  deploy:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [lint, test, security]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    steps:
      - uses: actions/checkout@v3
      
      - name: Deploy to server
        run: |
          echo "Deploying to production..."
          # Adicionar comandos de deploy aqui
```

### Pre-commit Hooks
```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.3.0
    hooks:
      - id: black
        language_version: python3.10

  - repo: https://github.com/pycqa/isort
    rev: 5.12.0
    hooks:
      - id: isort
        args: ["--profile", "black"]

  - repo: https://github.com/pycqa/flake8
    rev: 6.0.0
    hooks:
      - id: flake8
        args: ["--max-line-length=100", "--extend-ignore=E203,W503"]

  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.4.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-json
      - id: check-added-large-files
        args: ['--maxkb=1000']
      - id: check-merge-conflict
      - id: detect-private-key

  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.5
    hooks:
      - id: bandit
        args: ["-c", "pyproject.toml"]

# Instalar: pip install pre-commit
# Ativar: pre-commit install
# Executar manualmente: pre-commit run --all-files
```

### Docker (Containeriza√ß√£o)
```dockerfile
# Dockerfile
FROM python:3.10-slim

# Definir diret√≥rio de trabalho
WORKDIR /app

# Vari√°veis de ambiente
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1

# Instalar depend√™ncias do sistema
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copiar requirements e instalar depend√™ncias
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo da aplica√ß√£o
COPY . .

# Criar usu√°rio n√£o-root
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expor porta (se aplic√°vel)
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
  CMD python -c "import sys; sys.exit(0)"

# Comando para executar a aplica√ß√£o
CMD ["python", "run_dashboard.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build: .
    container_name: portfolio_analyzer
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - API_KEY=${API_KEY}
    volumes:
      - ./data:/app/data
      - ./relatorios:/app/relatorios
    restart: unless-stopped
    networks:
      - app-network

  # Exemplo: adicionar banco de dados
  # postgres:
  #   image: postgres:15
  #   environment:
  #     POSTGRES_DB: portfolio_db
  #     POSTGRES_USER: user
  #     POSTGRES_PASSWORD: ${DB_PASSWORD}
  #   volumes:
  #     - postgres_data:/var/lib/postgresql/data
  #   networks:
  #     - app-network

networks:
  app-network:
    driver: bridge

volumes:
  postgres_data:
```

### Configura√ß√£o de Ambiente
```bash
# .env.example - Template para vari√°veis de ambiente
# Copiar para .env e preencher valores reais

# Ambiente
ENVIRONMENT=development  # development, staging, production

# APIs
BINANCE_API_KEY=your_key_here
BINANCE_API_SECRET=your_secret_here
YAHOO_FINANCE_KEY=your_key_here

# Banco de Dados (se aplic√°vel)
DATABASE_URL=postgresql://user:password@localhost:5432/dbname

# Cache
CACHE_EXPIRY_HOURS=24
CACHE_DIR=data/cache

# Logging
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FILE=app.log

# Seguran√ßa
SECRET_KEY=your_secret_key_here
ALLOWED_HOSTS=localhost,127.0.0.1
```

```python
# config/settings.py - Carregar configura√ß√µes
import os
from dotenv import load_dotenv

load_dotenv()

class Settings:
    """Configura√ß√µes da aplica√ß√£o"""
    
    # Ambiente
    ENVIRONMENT = os.getenv("ENVIRONMENT", "development")
    DEBUG = ENVIRONMENT == "development"
    
    # APIs
    BINANCE_API_KEY = os.getenv("BINANCE_API_KEY")
    BINANCE_API_SECRET = os.getenv("BINANCE_API_SECRET")
    
    # Cache
    CACHE_EXPIRY_HOURS = int(os.getenv("CACHE_EXPIRY_HOURS", "24"))
    CACHE_DIR = os.getenv("CACHE_DIR", "data/cache")
    
    # Logging
    LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
    LOG_FILE = os.getenv("LOG_FILE", "app.log")
    
    @classmethod
    def validate(cls):
        """Valida configura√ß√µes obrigat√≥rias"""
        required = ["BINANCE_API_KEY", "BINANCE_API_SECRET"]
        missing = [key for key in required if not getattr(cls, key)]
        if missing:
            raise EnvironmentError(f"Vari√°veis obrigat√≥rias n√£o definidas: {', '.join(missing)}")

# Uso
settings = Settings()
settings.validate()
```

### Monitoramento e Logs
```python
# Configura√ß√£o de logging estruturado
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    """Formatter para logs em JSON"""
    def format(self, record):
        log_data = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }
        
        if record.exc_info:
            log_data["exception"] = self.formatException(record.exc_info)
        
        return json.dumps(log_data)

# Configurar
handler = logging.FileHandler('logs/app.json')
handler.setFormatter(JSONFormatter())

logger = logging.getLogger(__name__)
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# Uso
logger.info("Processando carteira", extra={"portfolio_id": "123", "value": 100000})
```

### Branch Strategy (GitFlow)
```
main (produ√ß√£o)
  ‚Üì
  ‚îî‚îÄ‚îÄ Merges apenas de release/ ou hotfix/
  
release/v1.1.0 (pr√©-produ√ß√£o)
  ‚Üì
  ‚îî‚îÄ‚îÄ Merges de develop quando features est√£o prontas
  
develop (homologa√ß√£o)
  ‚Üì
  ‚îî‚îÄ‚îÄ Merges de feature/, fix/, refactor/
  
feature/adicionar-fundos-imobiliarios (desenvolvimento)
feature/melhorar-cache
fix/corrigir-sharpe-ratio
refactor/reorganizar-apis
hotfix/bug-critico (emerg√™ncia ‚Üí direto para main)
```

### Checklist de Deploy
```markdown
## Pre-Deploy
- [ ] Todos os testes passando
- [ ] Cobertura de testes >= 80%
- [ ] Lint sem erros
- [ ] Documenta√ß√£o atualizada
- [ ] CHANGELOG.md atualizado
- [ ] Vers√£o incrementada corretamente
- [ ] Vari√°veis de ambiente configuradas
- [ ] Backup dos dados de produ√ß√£o realizado

## Deploy
- [ ] Build da aplica√ß√£o executado
- [ ] Testes de integra√ß√£o executados
- [ ] Deploy para staging executado
- [ ] Testes manuais em staging
- [ ] Deploy para produ√ß√£o executado
- [ ] Health checks passando

## Post-Deploy
- [ ] Monitoramento ativo
- [ ] Logs sendo coletados
- [ ] Performance dentro do esperado
- [ ] Funcionalidades principais testadas
- [ ] Rollback plan preparado
- [ ] Stakeholders notificados
```

---

## üìö Recursos Adicionais

### Ferramentas Recomendadas
- **Lint**: `black`, `flake8`, `isort`, `mypy`
- **Testing**: `pytest`, `pytest-cov`, `pytest-mock`
- **Security**: `bandit`, `safety`, `pip-audit`
- **Docs**: `sphinx`, `mkdocs`
- **Performance**: `cProfile`, `memory_profiler`, `py-spy`

### Links √öteis
- [PEP 8 - Style Guide](https://peps.python.org/pep-0008/)
- [PEP 257 - Docstring Conventions](https://peps.python.org/pep-0257/)
- [Conventional Commits](https://www.conventionalcommits.org/)
- [Semantic Versioning](https://semver.org/)
- [Python Type Hints](https://docs.python.org/3/library/typing.html)
- [pytest Documentation](https://docs.pytest.org/)
- [GitHub Actions](https://docs.github.com/actions)

---

## üìù Notas Finais

Este guia deve ser tratado como um documento vivo, atualizado conforme novas pr√°ticas s√£o adotadas e tecnologias evoluem.

**√öltima atualiza√ß√£o:** 06/10/2025  
**Mantenedor:** Equipe de Desenvolvimento  
**Pr√≥xima revis√£o:** 06/01/2026

---
